{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Finance Retail Analytics - Credit Risk Assessment\n",
                "\n",
                "## 1. Introduction\n",
                "This notebook analyzes financial data to predict whether a company will default on its net worth next year. We use data preprocessing, feature engineering (VIF), and machine learning models (Logistic Regression, Random Forest)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append(os.path.abspath(os.path.join('..')))\n",
                "\n",
                "from src.data_preprocessing import load_data, clean_column_names, handle_missing_values, scale_features\n",
                "from src.feature_engineering import calculate_vif, drop_high_vif_features\n",
                "from src.modeling import train_logistic_regression, get_logistic_predictions, train_random_forest\n",
                "from src.evaluation import get_performance_metrics, plot_confusion_matrix, plot_roc_curve"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading and Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = '../data/raw/FRA-Comp_Fin_Data.csv'\n",
                "df = load_data(data_path)\n",
                "df = clean_column_names(df)\n",
                "\n",
                "# Define Target\n",
                "df['default'] = np.where(df['Networth_Next_Year'] > 0, 0, 1)\n",
                "df = df.drop(['Networth_Next_Year'], axis=1) # Drop target proxy\n",
                "\n",
                "# Basic Cleaning (Dropping strict identifiers if any, similar to original notebook)\n",
                "# df = df.drop(['Num', 'Equity_face_value'], axis=1, errors='ignore') \n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Handling Missing Values\n",
                "Using KNN Imputation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_imputed = handle_missing_values(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train-Test Split and Scaling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X = df_imputed.drop('default', axis=1)\n",
                "y = df_imputed['default']\n",
                "\n",
                "# Drop non-numeric for VIF/Modeling consistency if any remain\n",
                "X = X.select_dtypes(include=[np.number])\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
                "\n",
                "X_train_scaled, X_test_scaled, scaler = scale_features(X_train, X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Feature Engineering (VIF)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_vif, X_test_vif = drop_high_vif_features(X_train_scaled, X_test_scaled, threshold=5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Model Training & Evaluation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Logistic Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "logit_model = train_logistic_regression(X_train_vif, y_train)\n",
                "print(logit_model.summary())\n",
                "\n",
                "y_pred_logit, y_prob_logit = get_logistic_predictions(logit_model, X_test_vif)\n",
                "print(get_performance_metrics(y_test, y_pred_logit))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rf_model = train_random_forest(X_train_scaled, y_train) # RF handles correlation better, using scaled features\n",
                "y_pred_rf = rf_model.predict(X_test_scaled)\n",
                "print(get_performance_metrics(y_test, y_pred_rf))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Conclusions\n",
                "Summary of findings and business recommendations."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}